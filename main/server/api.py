import base64
from io import BytesIO
import shutil
from pathlib import Path
import uuid
from fastapi import FastAPI, File, UploadFile, HTTPException
from langchain_core.messages import HumanMessage, AIMessage
from pydantic import BaseModel, Field
from typing import Dict
from main.modules.document_handler import extract_text_from_file, extract_from_image
from main.modules.process_vector_store import preprocess_text
from main.modules.rag_chat import rag_chat


app = FastAPI()

# Create upload directory
UPLOAD_DIR = Path("uploads")
UPLOAD_DIR.mkdir(exist_ok=True)

# Stores session-specific chat history and cleaned text for each session.
session_state: Dict[str, Dict] = {}

# Define the request model for the chat endpoint
class chatrequest(BaseModel):
    """Request model for chat endpoint containing user query and session ID.
    Attributes:
        query (dict): The user query and optional image in base64 format.
        session_id (str): The current chat session ID.
    """
    query: dict 
    session_id: str

# Define the response model for the chat endpoint
class ChatResponse(BaseModel):
    """Response model for chat endpoint containing chat history and response.
    Attributes:
        chat_history (list): List of chat messages in the session.
        response (str): Response generated by the RAG chat system.
    """
    chat_history: list = Field(..., description="List of chat messages in the session",
                               example=[
                                  {"role": "user", "content": "What is the capital of France?"},
                                  {"role": "assistant", "content": "The capital of France is Paris."}
                              ])
    response: str = Field(..., description="Response generated by the RAG chat system",
                          example="The capital of France is Paris.")
    
    
# Health check endpoint to verify API is running
@app.get("/")
async def home():
    """Health check endpoint to verify API is running.
    Returns:
        dict: A simple welcome message."""
    
    return {"message": "Welcome to the Multi-Format-RAG-Chat API"}


# Endpoint to upload a file, extract and preprocess its text, and initialize a chat session.
@app.post("/uploadfile")
async def create_upload_file(file: UploadFile = File(...)):
    """Upload a file, extract and preprocess its text, and initialize a chat session.
    Args:
        file (UploadFile): The file to be uploaded.
    Returns:
        dict: A message indicating success and the session ID."""

    if file.filename == "":
        raise HTTPException(status_code=400, detail="No file selected")

    file_path = UPLOAD_DIR / file.filename

    # Save the uploaded file to the upload directory
    with open(file_path, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)

    try:

        # Extract text from the uploaded file
        # This will handle various file types like PDF, DOCX, TXT, etc.
        extracted_text = extract_text_from_file(str(file_path))

        # Get cleaned Processed text
        # from the extracted text to prepare it for vectorization
        cleaned_text = preprocess_text(extracted_text)  

        # Generate unique session ID
        session_id = str(uuid.uuid4())

        # Store session state
        # This will hold the chat history and cleaned text for the session
        # This allows us to maintain context across multiple interactions       
        session_state[session_id] = {
            "chat_history": [AIMessage(content="Hi! I've processed your PDF files. How can I help you?")], 
            "cleaned_text": cleaned_text
        }       
        
        return {"message": "File processed successfully", "session_id": session_id}
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error processing file: {str(e)}")
    
    
# Endpoint for RAG chat with the given query and context.
@app.post("/rag_chat", response_model = ChatResponse)
async def rag_chat_endpoint(request: chatrequest):
    """Endpoint for RAG chat with the given query and context.
    Args:
        request (chatrequest): The request containing user query and session ID.
    Returns:
        ChatResponse: The response containing chat history and generated response."""
    
    # Validate session ID
    session = session_state.get(request.session_id)
    if not session:
        raise HTTPException(status_code=404, detail="Session not found")
    
    # Retrieve chat history and cleaned text from session
    chat_history = session["chat_history"]
    cleaned_text = session["cleaned_text"]
    
    # Extract user query and image if present
    # If the user query is empty, returns an error
    # If an image is provided, decode it and extract text from the image
    # This allows to combine the query and image context for the RAG chat
    user_query = request.query["query"] if "query" in request.query else ""
    image_base64 = request.query["image"] if "image" in request.query else None
    
    try:

        combined_input = user_query
        
        # Process image if present
        if image_base64:
            # Decode the base64 image
            image_data = base64.b64decode(image_base64)

            # Create a BytesIO object from the decoded image data
            image = BytesIO(image_data)

            # Extract text from the image
            # This will use OCR to extract text from the image
            image_context = extract_from_image(image)
            
            # and combine it with the user query
            if image_context.strip():
                combined_input = f"{user_query}\n\nImage content: {image_context}".strip()
        
        # Only proceed if we have some input
        if not combined_input.strip():
            raise HTTPException(status_code=400, detail="No query or image content provided")
        
        # Add user message to history (store the original query, not combined)
        # This allows to maintain the original text user query in the chat history
        chat_history.append(HumanMessage(content=user_query if user_query else "Uploaded an image"))
        
        # Get RAG response with combined input
        response = rag_chat(combined_input, chat_history, cleaned_text)
        
        # Add AI response to history
        if response:
            chat_history.append(AIMessage(content=response))
            
            # Convert history to JSON-safe format
            # This is to ensure the chat history can be serialized properly
            history_json = [{"role": msg.type, "content": msg.content} for msg in chat_history]
            
            return {"chat_history": history_json, "response": response}
        else:
            raise HTTPException(status_code=500, detail="No response generated")
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error in RAG chat: {str(e)}")
    
    
    
